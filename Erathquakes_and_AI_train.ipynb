{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Erathquakes_and_AI_train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPsxnV8F2Au8BCR+E7q7f+s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaimaMunir/Predicting-Local-Earthquakes/blob/main/Erathquakes_and_AI_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0ddOCv_GmQX"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, GlobalAvgPool2D, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from io import open\n",
        "import json\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPool2D, AvgPool2D, GlobalMaxPool2D, GlobalAvgPool2D, BatchNormalization, add, Input\n",
        "#from tensorflow.python.keras.models import Mode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EqNvO6kG-NT"
      },
      "source": [
        "\n",
        "\n",
        "def resnet_module(input, channel_depth, strided_pool=False ):\n",
        "    residual_input = input\n",
        "    stride = 1\n",
        "\n",
        "    if(strided_pool):\n",
        "        stride = 2\n",
        "        residual_input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\")(residual_input)\n",
        "        residual_input = BatchNormalization()(residual_input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth/4), kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=1, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "\n",
        "    input = add([input, residual_input])\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "\n",
        "def resnet_first_block_first_module(input, channel_depth):\n",
        "    residual_input = input\n",
        "    stride = 1\n",
        "\n",
        "    residual_input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\")(residual_input)\n",
        "    residual_input = BatchNormalization()(residual_input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth/4), kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "\n",
        "    input = add([input, residual_input])\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "def resnet_block(input, channel_depth, num_layers, strided_pool_first = False ):\n",
        "    for i in range(num_layers):\n",
        "        pool = False\n",
        "        if(i == 0 and strided_pool_first):\n",
        "            pool = True\n",
        "        input = resnet_module(input, channel_depth, strided_pool=pool)\n",
        "\n",
        "    return input\n",
        "\n",
        "def ResNet50(include_top=True, non_top_pooling=None, model_input=None, num_classes=3, weights='imagenet', model_path=\"\"):\n",
        "    layers = [3,4,6,3]\n",
        "    channel_depths = [256, 512, 1024, 2048]\n",
        "\n",
        "    input_object = model_input\n",
        "\n",
        "\n",
        "    output = Conv2D(64, kernel_size=7, strides=2, padding=\"same\")(input_object)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation(\"relu\")(output)\n",
        "\n",
        "    output = MaxPool2D(pool_size=(3,3), strides=(2,2))(output)\n",
        "    output = resnet_first_block_first_module(output, channel_depths[0])\n",
        "\n",
        "\n",
        "    for i in range(4):\n",
        "        channel_depth = channel_depths[i]\n",
        "        num_layers = layers[i]\n",
        "\n",
        "        strided_pool_first = True\n",
        "        if(i == 0):\n",
        "            strided_pool_first = False\n",
        "            num_layers = num_layers - 1\n",
        "        output = resnet_block(output, channel_depth=channel_depth, num_layers=num_layers, strided_pool_first=strided_pool_first)\n",
        "\n",
        "    if(include_top):\n",
        "        output = GlobalAvgPool2D(name=\"global_avg_pooling\")(output)\n",
        "        output = Dense(num_classes)(output)\n",
        "        output = Activation(\"softmax\")(output)\n",
        "    else:\n",
        "        if (non_top_pooling == \"Average\"):\n",
        "            output = GlobalAvgPool2D()(output)\n",
        "        elif (non_top_pooling == \"Maximum\"):\n",
        "            output = GlobalMaxPool2D()(output)\n",
        "        elif (non_top_pooling == None):\n",
        "            pass\n",
        "\n",
        "    model = Model(inputs=input_object, outputs=output)\n",
        "\n",
        "    if(weights == \"imagenet\"):\n",
        "        weights_path = model_path\n",
        "        model.load_weights(weights_path)\n",
        "    elif (weights == \"trained\"):\n",
        "        weights_path = model_path\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "class ModelTraining:\n",
        "    \"\"\"\n",
        "        This is the Model training class, that allows you to define a deep learning network\n",
        "        from ResNet50.\n",
        "        Once you instantiate this class, you must call:\n",
        "\n",
        "        *\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.__modelType = \"\"\n",
        "        self.__use_pretrained_model = False\n",
        "        self.__data_dir = \"\"\n",
        "        self.__train_dir = \"\"\n",
        "        self.__test_dir = \"\"\n",
        "        self.__num_epochs = 8\n",
        "        self.__trained_model_dir = \"\"\n",
        "        self.__model_class_dir = \"\"\n",
        "        self.__initial_learning_rate = 1e-3\n",
        "        self.__model_collection = []\n",
        "\n",
        "\n",
        "    def setModelTypeAsResNet(self):\n",
        "        \"\"\"\n",
        "         'setModelTypeAsResNet()' is used to set the model type to the ResNet model\n",
        "                for the training instance object .\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.__modelType = \"resnet\"\n",
        "\n",
        "    def setDataDirectory(self, data_directory=\"\"):\n",
        "        \"\"\"\n",
        "                 'setDataDirectory()' is required to set the path to which the data/dataset to be used for\n",
        "                 training is kept. The directory can have any name, but it must have 'train' and 'test'\n",
        "                 sub-directory. In the 'train' and 'test' sub-directories, there must be sub-directories\n",
        "                 with each having it's name corresponds to the name/label of the object whose images are\n",
        "                to be kept. The structure of the 'test' and 'train' folder must be as follows:\n",
        "\n",
        "                >> train >> class1 >> class1_train_images\n",
        "                         >> class2 >> class2_train_images\n",
        "                         >> class3 >> class3_train_images\n",
        "                         >> class4 >> class4_train_images\n",
        "                         >> class5 >> class5_train_images\n",
        "\n",
        "                >> test >> class1 >> class1_test_images\n",
        "                        >> class2 >> class2_test_images\n",
        "                        >> class3 >> class3_test_images\n",
        "                        >> class4 >> class4_test_images\n",
        "                        >> class5 >> class5_test_images\n",
        "\n",
        "                :return:\n",
        "                \"\"\"\n",
        "\n",
        "        self.__data_dir = data_directory\n",
        "        self.__train_dir = os.path.join(self.__data_dir, \"train\")\n",
        "        self.__test_dir = os.path.join(self.__data_dir, \"test\")\n",
        "        self.__trained_model_dir = os.path.join(self.__data_dir, \"models\")\n",
        "        self.__model_class_dir = os.path.join(self.__data_dir, \"json\")\n",
        "\n",
        "    def lr_schedule(self, epoch):\n",
        "\n",
        "        # Learning Rate Schedule\n",
        "\n",
        "\n",
        "        lr = self.__initial_learning_rate\n",
        "        total_epochs = self.__num_epochs\n",
        "\n",
        "        check_1 = int(total_epochs * 0.9)\n",
        "        check_2 = int(total_epochs * 0.8)\n",
        "        check_3 = int(total_epochs * 0.6)\n",
        "        check_4 = int(total_epochs * 0.4)\n",
        "\n",
        "        if epoch > check_1:\n",
        "            lr *= 1e-4\n",
        "        elif epoch > check_2:\n",
        "            lr *= 1e-3\n",
        "        elif epoch > check_3:\n",
        "            lr *= 1e-2\n",
        "        elif epoch > check_4:\n",
        "            lr *= 1e-1\n",
        "\n",
        "\n",
        "        return lr\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def trainModel(self, num_objects, num_experiments=8, enhance_data=False, batch_size = 16, initial_learning_rate=1e-3, show_network_summary=False):\n",
        "\n",
        "        \"\"\"\n",
        "                 'trainModel()' function starts the actual training. It accepts the following values:\n",
        "                 - num_objects , which is the number of classes present in the dataset that is to be used for training\n",
        "                 - num_experiments , also known as epochs, it is the number of times the network will train on all the training dataset\n",
        "                 - enhance_data (optional) , this is used to modify the dataset and create more instance of the training set to enhance the training result\n",
        "                 - batch_size (optional) , due to memory constraints, the network trains on a batch at once, until all the training set is exhausted.\n",
        "                                            The value is set to 32 by default, but can be increased or decreased depending on the meormory of the\n",
        "                                            compute used for training. The batch_size is conventionally set to 16, 32, 64, 128.\n",
        "                 - initial_learning_rate(optional) , this value is used to adjust the weights generated in the network. You rae advised\n",
        "                                                     to keep this value as it is if you don't have deep understanding of this concept.\n",
        "                 - show_network_summary(optional) , this value is used to show the structure of the network should you desire to see it.\n",
        "                                                    Itis set to False by default\n",
        "                 - training_image_size(optional) , this value is used to define the image size on which the model will be trained. The\n",
        "                                            value is 224 by default and is kept at a minimum of 100.\n",
        "\n",
        "                 *\n",
        "\n",
        "                :param num_objects:\n",
        "                :param num_experiments:\n",
        "                :param enhance_data:\n",
        "                :param batch_size:\n",
        "                :param initial_learning_rate:\n",
        "                :param show_network_summary:\n",
        "                :param training_image_size:\n",
        "                :return:\n",
        "                \"\"\"\n",
        "        self.__num_epochs = num_experiments\n",
        "        self.__initial_learning_rate = initial_learning_rate\n",
        "        lr_scheduler = LearningRateScheduler(self.lr_schedule)\n",
        "\n",
        "\n",
        "        num_classes = num_objects\n",
        "\n",
        "        #if(training_image_size < 100):\n",
        "         #   warnings.warn(\"The specified training_image_size {} is less than 100. Hence the training_image_size will default to 100.\".format(training_image_size))\n",
        "          #  training_image_size = 100\n",
        "\n",
        "\n",
        "\n",
        "        image_input = Input(shape=(432, 288, 3))\n",
        "        if (self.__modelType == \"resnet\"):\n",
        "            model = ResNet50(weights=\"custom\", num_classes=num_classes, model_input=image_input)\n",
        "\n",
        "        optimizer = Adam(lr=self.__initial_learning_rate, decay=1e-4)\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "        if (show_network_summary == True):\n",
        "            model.summary()\n",
        "\n",
        "        model_name = 'model_ex-{epoch:03d}_acc-{val_loss:03f}.h5'\n",
        "\n",
        "        if not os.path.isdir(self.__trained_model_dir):\n",
        "            os.makedirs(self.__trained_model_dir)\n",
        "\n",
        "        if not os.path.isdir(self.__model_class_dir):\n",
        "            os.makedirs(self.__model_class_dir)\n",
        "\n",
        "        model_path = os.path.join(self.__trained_model_dir, model_name)\n",
        "\n",
        "        checkpoint = ModelCheckpoint(filepath=model_path,\n",
        "                                     monitor='val_loss',\n",
        "                                     verbose=1,\n",
        "                                     save_weights_only=True,\n",
        "                                     period=1)\n",
        "\n",
        "        if (enhance_data == True):\n",
        "            print(\"Using Enhanced Data Generation\")\n",
        "\n",
        "        height_shift = 0\n",
        "        width_shift = 0\n",
        "        if (enhance_data == True):\n",
        "            height_shift = 0.1\n",
        "            width_shift = 0.1\n",
        "\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255,\n",
        "            horizontal_flip=enhance_data, height_shift_range=height_shift, width_shift_range=width_shift)\n",
        "\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            rescale=1. / 255)\n",
        "\n",
        "        train_generator = train_datagen.flow_from_directory(self.__train_dir, target_size=(432, 288),\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode=\"categorical\")\n",
        "        test_generator = test_datagen.flow_from_directory(self.__test_dir, target_size=(432, 288),\n",
        "                                                          batch_size=batch_size,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "        class_indices = train_generator.class_indices\n",
        "        class_json = {}\n",
        "        for eachClass in class_indices:\n",
        "            class_json[str(class_indices[eachClass])] = eachClass\n",
        "\n",
        "        with open(os.path.join(self.__model_class_dir, \"model_class.json\"), \"w+\") as json_file:\n",
        "            json.dump(class_json, json_file, indent=4, separators=(\",\", \" : \"),\n",
        "                      ensure_ascii=True)\n",
        "            json_file.close()\n",
        "        print(\"JSON Mabpping for the model classes saved to \", os.path.join(self.__model_class_dir, \"model_class.json\"))\n",
        "\n",
        "        num_train = len(train_generator.filenames)\n",
        "        num_test = len(test_generator.filenames)\n",
        "        print(\"Number of experiments (Epochs) : \", self.__num_epochs)\n",
        "\n",
        "        #\n",
        "        model.fit_generator(train_generator, steps_per_epoch=int(num_train / batch_size), epochs=self.__num_epochs,\n",
        "                            validation_data=test_generator,\n",
        "                            validation_steps=int(num_test / batch_size), callbacks=[checkpoint, lr_scheduler])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1FT4WWfHBeH"
      },
      "source": [
        "#create object of class\n",
        "model_trainer = ModelTraining()\n",
        "model_trainer.setModelTypeAsResNet()\n",
        "model_trainer.setDataDirectory(\"/content/drive/MyDrive/EQ_data\")\n",
        "model_trainer.trainModel(num_objects=2, num_experiments=8, enhance_data=True, batch_size=40, show_network_summary=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}