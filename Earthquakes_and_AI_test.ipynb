{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Earthquakes_and_AI_test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyYXdV1bFEDKSY9sP5ItaP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaimaMunir/Predicting-Local-Earthquakes/blob/main/Earthquakes_and_AI_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMlU53wrIOR5"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, GlobalAvgPool2D, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from PIL import Image\n",
        "import os\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from io import open\n",
        "import json\n",
        "import numpy as np\n",
        "import warnings\n",
        "from tensorflow.python import keras\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Activation, Flatten, Conv2D, MaxPool2D, AvgPool2D, GlobalMaxPool2D, GlobalAvgPool2D, BatchNormalization, add, Input\n",
        "#from tensorflow.python.keras.models import Mode\n",
        "import sys\n",
        "\n",
        "\n",
        "\n",
        "CLASS_INDEX = None\n",
        "\n",
        "def preprocess_input(x):\n",
        "    \"\"\"Preprocesses a tensor encoding a batch of images.\n",
        "\n",
        "    # Arguments\n",
        "        x: input Numpy tensor, 4D.\n",
        "        data_format: data format of the image tensor.\n",
        "\n",
        "    # Returns\n",
        "        Preprocessed tensor.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # 'RGB'->'BGR'\n",
        "    x *= (1./255)\n",
        "\n",
        "    return x\n",
        "\n",
        "def decode_predictions(preds, top=5, model_json=\"\"):\n",
        "\n",
        "    global CLASS_INDEX\n",
        "\n",
        "    if CLASS_INDEX is None:\n",
        "        CLASS_INDEX = json.load(open(model_json))\n",
        "    results = []\n",
        "    for pred in preds:\n",
        "        top_indices = pred.argsort()[-top:][::-1]\n",
        "        for i in top_indices:\n",
        "            each_result = []\n",
        "            each_result.append(CLASS_INDEX[str(i)])\n",
        "            each_result.append(pred[i])\n",
        "            results.append(each_result)\n",
        "\n",
        "    return results\n",
        "\n",
        "def resnet_module(input, channel_depth, strided_pool=False ):\n",
        "    residual_input = input\n",
        "    stride = 1\n",
        "\n",
        "    if(strided_pool):\n",
        "        stride = 2\n",
        "        residual_input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\")(residual_input)\n",
        "        residual_input = BatchNormalization()(residual_input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth/4), kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=1, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "\n",
        "    input = add([input, residual_input])\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "\n",
        "def resnet_first_block_first_module(input, channel_depth):\n",
        "    residual_input = input\n",
        "    stride = 1\n",
        "\n",
        "    residual_input = Conv2D(channel_depth, kernel_size=1, strides=1, padding=\"same\")(residual_input)\n",
        "    residual_input = BatchNormalization()(residual_input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth/4), kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(int(channel_depth / 4), kernel_size=3, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    input = Conv2D(channel_depth, kernel_size=1, strides=stride, padding=\"same\")(input)\n",
        "    input = BatchNormalization()(input)\n",
        "\n",
        "    input = add([input, residual_input])\n",
        "    input = Activation(\"relu\")(input)\n",
        "\n",
        "    return input\n",
        "\n",
        "\n",
        "def resnet_block(input, channel_depth, num_layers, strided_pool_first = False ):\n",
        "    for i in range(num_layers):\n",
        "        pool = False\n",
        "        if(i == 0 and strided_pool_first):\n",
        "            pool = True\n",
        "        input = resnet_module(input, channel_depth, strided_pool=pool)\n",
        "\n",
        "    return input\n",
        "\n",
        "def ResNet50(include_top=True, non_top_pooling=None, model_input=None, num_classes=1000, weights='imagenet', model_path=\"\"):\n",
        "    layers = [3,4,6,3]\n",
        "    channel_depths = [256, 512, 1024, 2048]\n",
        "\n",
        "    input_object = model_input\n",
        "\n",
        "\n",
        "    output = Conv2D(64, kernel_size=7, strides=2, padding=\"same\")(input_object)\n",
        "    output = BatchNormalization()(output)\n",
        "    output = Activation(\"relu\")(output)\n",
        "\n",
        "    output = MaxPool2D(pool_size=(3,3), strides=(2,2))(output)\n",
        "    output = resnet_first_block_first_module(output, channel_depths[0])\n",
        "\n",
        "\n",
        "    for i in range(4):\n",
        "        channel_depth = channel_depths[i]\n",
        "        num_layers = layers[i]\n",
        "\n",
        "        strided_pool_first = True\n",
        "        if(i == 0):\n",
        "            strided_pool_first = False\n",
        "            num_layers = num_layers - 1\n",
        "        output = resnet_block(output, channel_depth=channel_depth, num_layers=num_layers, strided_pool_first=strided_pool_first)\n",
        "\n",
        "    if(include_top):\n",
        "        output = GlobalAvgPool2D(name=\"global_avg_pooling\")(output)\n",
        "        output = Dense(num_classes)(output)\n",
        "        output = Activation(\"softmax\")(output)\n",
        "    else:\n",
        "        if (non_top_pooling == \"Average\"):\n",
        "            output = GlobalAvgPool2D()(output)\n",
        "        elif (non_top_pooling == \"Maximum\"):\n",
        "            output = GlobalMaxPool2D()(output)\n",
        "        elif (non_top_pooling == None):\n",
        "            pass\n",
        "\n",
        "    model = Model(inputs=input_object, outputs=output)\n",
        "\n",
        "    if(weights == \"imagenet\"):\n",
        "        weights_path = model_path\n",
        "        model.load_weights(weights_path)\n",
        "    elif (weights == \"trained\"):\n",
        "        weights_path = model_path\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "class CustomImagePrediction:\n",
        "    \"\"\"\n",
        "                This is the image prediction class for custom models trained with the 'ModelTraining' class. It provides support for 4 different models which are:\n",
        "                 ResNet50, SqueezeNet, DenseNet121 and Inception V3. After instantiating this class, you can set it's properties and\n",
        "                 make image predictions using it's pre-defined functions.\n",
        "\n",
        "                 The following functions are required to be called before a prediction can be made\n",
        "                 * setModelPath() , path to your custom model\n",
        "                 * setJsonPath , , path to your custom model's corresponding JSON file\n",
        "                 * At least of of the following and it must correspond to the model set in the setModelPath()\n",
        "                  [setModelTypeAsSqueezeNet(), setModelTypeAsResNet(), setModelTypeAsDenseNet, setModelTypeAsInceptionV3]\n",
        "                 * loadModel() [This must be called once only before making a prediction]\n",
        "\n",
        "                 Once the above functions have been called, you can call the predictImage() function of the prediction instance\n",
        "                 object at anytime to predict an image.\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.__modelType = \"\"\n",
        "        self.modelPath = \"\"\n",
        "        self.jsonPath = \"\"\n",
        "        self.numObjects = 13\n",
        "        self.__modelLoaded = False\n",
        "        self.__model_collection = []\n",
        "        self.__input_image_size = 224\n",
        "\n",
        "    def setModelPath(self, model_path):\n",
        "        \"\"\"\n",
        "        'setModelPath()' function is required and is used to set the file path to the model adopted from the list of the\n",
        "        available 4 model types. The model path must correspond to the model type set for the prediction instance object.\n",
        "\n",
        "        :param model_path:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.modelPath = model_path\n",
        "\n",
        "    def setJsonPath(self, model_json):\n",
        "        \"\"\"\n",
        "        'setJsonPath()'\n",
        "\n",
        "        :param model_path:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.jsonPath = model_json\n",
        "\n",
        "    def setModelTypeAsResNet(self):\n",
        "        \"\"\"\n",
        "         'setModelTypeAsResNet()' is used to set the model type to the ResNet model\n",
        "                for the prediction instance object .\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        self.__modelType = \"resnet\"\n",
        "\n",
        "    def loadModel(self, prediction_speed=\"normal\", num_objects=10):\n",
        "        \"\"\"\n",
        "        'loadModel()' function is used to load the model structure into the program from the file path defined\n",
        "        in the setModelPath() function. This function receives an optional value which is \"prediction_speed\".\n",
        "        The value is used to reduce the time it takes to predict an image, down to about 50% of the normal time,\n",
        "        with just slight changes or drop in prediction accuracy, depending on the nature of the image.\n",
        "        * prediction_speed (optional); Acceptable values are \"normal\", \"fast\", \"faster\" and \"fastest\"\n",
        "\n",
        "        :param prediction_speed :\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        self.numObjects = num_objects\n",
        "\n",
        "        if (prediction_speed == \"normal\"):\n",
        "            self.__input_image_size = 224\n",
        "        elif (prediction_speed == \"fast\"):\n",
        "            self.__input_image_size = 160\n",
        "        elif (prediction_speed == \"faster\"):\n",
        "            self.__input_image_size = 120\n",
        "        elif (prediction_speed == \"fastest\"):\n",
        "            self.__input_image_size = 100\n",
        "\n",
        "        if (self.__modelLoaded == False):\n",
        "\n",
        "            image_input = Input(shape=(self.__input_image_size, self.__input_image_size, 3))\n",
        "\n",
        "            if (self.__modelType == \"\"):\n",
        "                raise ValueError(\"You must set a valid model type before loading the model.\")\n",
        "\n",
        "            elif (self.__modelType == \"resnet\"):\n",
        "                #import numpy as np\n",
        "                from tensorflow.python.keras.preprocessing import image\n",
        "                #from resnet50 import ResNet50\n",
        "                #from custom_utils import preprocess_input\n",
        "                #from custom_utils import decode_predictions\n",
        "                try:\n",
        "                    model = ResNet50(model_path=self.modelPath, weights=\"trained\", model_input=image_input, num_classes=self.numObjects)\n",
        "                    self.__model_collection.append(model)\n",
        "                    self.__modelLoaded = True\n",
        "                except:\n",
        "                    raise ValueError(\"You have specified an incorrect path to the ResNet model file.\")\n",
        "\n",
        "    def predictImage(self, image_input, result_count=1, input_type=\"file\"):\n",
        "        \"\"\"\n",
        "        'predictImage()' function is used to predict a given image by receiving the following arguments:\n",
        "            * input_type (optional) , the type of input to be parsed. Acceptable values are \"file\", \"array\" and \"stream\"\n",
        "            * image_input , file path/numpy array/image file stream of the image.\n",
        "            * result_count (optional) , the number of predictions to be sent which must be whole numbers between\n",
        "                1 and the number of classes present in the model\n",
        "\n",
        "        This function returns 2 arrays namely 'prediction_results' and 'prediction_probabilities'. The 'prediction_results'\n",
        "        contains possible objects classes arranged in descending of their percentage probabilities. The 'prediction_probabilities'\n",
        "        contains the percentage probability of each object class. The position of each object class in the 'prediction_results'\n",
        "        array corresponds with the positions of the percentage possibilities in the 'prediction_probabilities' array.\n",
        "\n",
        "\n",
        "        :param input_type:\n",
        "        :param image_input:\n",
        "        :param result_count:\n",
        "        :return prediction_results, prediction_probabilities:\n",
        "        \"\"\"\n",
        "        prediction_results = []\n",
        "        prediction_probabilities = []\n",
        "        if (self.__modelLoaded == False):\n",
        "            raise ValueError(\"You must call the loadModel() function before making predictions.\")\n",
        "\n",
        "        else:\n",
        "\n",
        "            if (self.__modelType == \"resnet\"):\n",
        "\n",
        "                model = self.__model_collection[0]\n",
        "\n",
        "                #from custom_utils import preprocess_input\n",
        "                #from custom_utils import decode_predictions\n",
        "                if (input_type == \"file\"):\n",
        "                    try:\n",
        "                        image_to_predict = image.load_img(image_input, target_size=(\n",
        "                        self.__input_image_size, self.__input_image_size))\n",
        "                        image_to_predict = image.img_to_array(image_to_predict, data_format=\"channels_last\")\n",
        "                        image_to_predict = np.expand_dims(image_to_predict, axis=0)\n",
        "\n",
        "                        image_to_predict = preprocess_input(image_to_predict)\n",
        "                    except:\n",
        "                        raise ValueError(\"You have set a path to an invalid image file.\")\n",
        "                elif (input_type == \"array\"):\n",
        "                    try:\n",
        "                        image_input = Image.fromarray(np.uint8(image_input))\n",
        "                        image_input = image_input.resize((self.__input_image_size, self.__input_image_size))\n",
        "                        image_input = np.expand_dims(image_input, axis=0)\n",
        "                        image_to_predict = image_input.copy()\n",
        "                        image_to_predict = np.asarray(image_to_predict, dtype=np.float64)\n",
        "                        image_to_predict = preprocess_input(image_to_predict)\n",
        "                    except:\n",
        "                        raise ValueError(\"You have parsed in a wrong numpy array for the image\")\n",
        "                elif (input_type == \"stream\"):\n",
        "                    try:\n",
        "                        image_input = Image.open(image_input)\n",
        "                        image_input = image_input.resize((self.__input_image_size, self.__input_image_size))\n",
        "                        image_input = np.expand_dims(image_input, axis=0)\n",
        "                        image_to_predict = image_input.copy()\n",
        "                        image_to_predict = np.asarray(image_to_predict, dtype=np.float64)\n",
        "                        image_to_predict = preprocess_input(image_to_predict)\n",
        "                    except:\n",
        "                        raise ValueError(\"You have parsed in a wrong stream for the image\")\n",
        "\n",
        "                prediction = model.predict(x=image_to_predict, steps=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                try:\n",
        "\n",
        "                    predictiondata = decode_predictions(prediction, top=int(result_count), model_json=self.jsonPath)\n",
        "\n",
        "                    for result in predictiondata:\n",
        "                        prediction_results.append(str(result[0]))\n",
        "                        prediction_probabilities.append(str(result[1] * 100))\n",
        "\n",
        "\n",
        "                except:\n",
        "                    raise ValueError(\"An error occured! Try again.\")\n",
        "\n",
        "                return prediction_results, prediction_probabilities\n",
        "\n",
        "\n",
        "def main(argv):\n",
        "    \"\"\"\n",
        "    Main function.\n",
        "    \"\"\"\n",
        "    #create object  class\n",
        "    execution_path = os.getcwd()\n",
        "\n",
        "    prediction = CustomImagePrediction()\n",
        "    prediction.setModelTypeAsResNet()\n",
        "    prediction.setModelPath(\"model_ex-003_acc-0.139158.h5\")\n",
        "    prediction.setJsonPath(\"model_class.json\")\n",
        "    prediction.loadModel(num_objects=2)\n",
        "\n",
        "    predictions, probabilities = prediction.predictImage(\"test_images/\"+argv, result_count=2)\n",
        "\n",
        "    for eachPrediction, eachProbability in zip(predictions, probabilities):\n",
        "        print(eachPrediction , \" : \" , eachProbability)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(sys.argv[1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}